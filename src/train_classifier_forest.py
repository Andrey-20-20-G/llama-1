import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.preprocessing import StandardScaler
from scipy.sparse import hstack
import joblib
import os

from text_features import calculate_handcrafted_features, calculate_tfidf_features

MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'rf_classifier.joblib')


def train_models():
    print("[INFO] –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç...")
    df = pd.read_csv("data/dataset.csv")

    # 1. –í—ã—á–∏—Å–ª—è–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_feats = calculate_handcrafted_features(df)
    tfidf_matrix, tfidf_features = calculate_tfidf_features(df)

    print("[INFO] –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∏—á–∏...")

    # 2. –ü–æ–ª—É—á–∞–µ–º —á–∏—Å–ª–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    numeric_feats = df_feats[['n_sentences', 'n_words', 'avg_word_length',
                              'avg_sent_length', 'unique_tokens', 'stopword_ratio']]

    scaler = StandardScaler()
    scaled_feats = scaler.fit_transform(numeric_feats)

    # 3. –û–±—ä–µ–¥–∏–Ω—è–µ–º TF-IDF + –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    X_combined = hstack([tfidf_matrix, scaled_feats])
    y = df_feats['label'].values

    # 4. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    X_train, X_test, y_train, y_test = train_test_split(
        X_combined, y, test_size=0.2, random_state=42
    )

    # 5. –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
    print("[INFO] –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
    clf = RandomForestClassifier(n_estimators=150, random_state=42)
    clf.fit(X_train, y_train)

    # 6. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    y_pred = clf.predict(X_test)

    # 7. –ú–µ—Ç—Ä–∏–∫–∏
    print("\nüìä Classification report:")
    print(classification_report(y_test, y_pred))

    print("üìâ Confusion matrix:")
    print(confusion_matrix(y_test, y_pred))

    # 8. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)
    joblib.dump(clf, MODEL_PATH)
    joblib.dump(scaler, 'models/scaler.joblib')
    joblib.dump(tfidf_features, 'models/tfidf_vocab.joblib')  # –î–æ–±–∞–≤–∏—Ç—å
    print(f"[INFO] –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")


if __name__ == "__main__":
    train_models()
    